{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n",
      "Failed to get the page content.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a request to the website\n",
    "base_url = \"https://scholar.google.ca/scholar?hl=en&as_sdt={}%2C5&q=general+surgery&btnG=&oq=general+sur\"\n",
    "\n",
    "\n",
    "# Define the number of pages to scrape\n",
    "pages = 10\n",
    "\n",
    "# Define the number of results per page\n",
    "results_per_page = 10\n",
    "\n",
    "# Loop through each page of results\n",
    "for page_number in range(pages):\n",
    "    # Calculate the starting index for the current page\n",
    "    start = (page_number * results_per_page)\n",
    "\n",
    "    # Format the URL for the current page\n",
    "    url = base_url.format(start)\n",
    "\n",
    "    # Send a request to the website\n",
    "    res = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if res.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Find all the links in the HTML\n",
    "        links = soup.find_all(\"a\")\n",
    "\n",
    "        # Filter the links to find the ones for the papers\n",
    "        paper_links = []\n",
    "        for link in links:\n",
    "            href = link.get(\"href\")\n",
    "            if href is not None and href.endswith(\".pdf\"):\n",
    "                paper_links.append(href)\n",
    "        \n",
    "        # Print the URLs\n",
    "        for link in paper_links:\n",
    "            print(link)\n",
    "\n",
    "        # Check if any links were found\n",
    "        if len(paper_links) == 0:\n",
    "            print(\"No links were found.\")\n",
    "    else:\n",
    "        print(\"Failed to get the page content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paper_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m delay \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Loop through each URL\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m paper_links:\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Send a request to the URL with retries\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         res \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mget(link, timeout\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, retries\u001b[39m=\u001b[39mretries)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paper_links' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the number of retries for the connection\n",
    "retries = 5\n",
    "\n",
    "# Define the delay between each request (in seconds)\n",
    "delay = 2\n",
    "\n",
    "# Loop through each URL\n",
    "for link in paper_links:\n",
    "    # Send a request to the URL with retries\n",
    "    try:\n",
    "        res = session.get(link, timeout=10, retries=retries)\n",
    "        # Check if the request was successful\n",
    "        if res.status_code == 200:\n",
    "            # Save the response to a file\n",
    "            with open(\"paper.txt\", \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "        # Wait for the specified delay before making the next request\n",
    "        time.sleep(delay)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Print the error message if there was a failure in the request\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "320e4e428c58c70c5aac27ce1fa4824b565dff6a3763e317ddfa8e50567a3cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
